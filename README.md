# Class-imbalanceness-in-ML


***
Spend enough time doing Machine Learning problems and you will definitely come across datasets having imbalanced data distribution. In imbalanced data, majority classes dominate over minority classes. In other words, number of observations belonging to one class are significantly higher(or lower) than the other class(es).

Since most machine learning algorithms assume that data is equally distributed, applying them on imbalanced data often results in bias towards majority classes and poor classification of minority classes. That's why classical data imbalance problem is recognized as one of the major problems in the field of machine learning.

The importance of knowing which sampling method to use is as important knowing if using sampling methods will achieve increase in model performance.

As a thumb rule, use sampling methods only when you have enough and varied samples of minority class. Sampling usually helps when the model is biased towards majority class despite having a good sample of minority class. It's wishful thinking to assume sampling methods will magically improve the quality of minority target class.

In this project we will discover ways to tackle class imbalance problems in machine learning.
